import streamlit as st
import os
from dotenv import load_dotenv
import fitz  # PyMuPDF
from PIL import Image

# --- LangChain ‡¶á‡¶Æ‡ßç‡¶™‡ßã‡¶∞‡ßç‡¶ü ---
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

load_dotenv()

st.set_page_config(page_title="PSNS: Study Notes", page_icon="üìö", layout="wide")
st.title("üìö Personal Study Notes Searcher")

# API Key ‡¶ö‡ßá‡¶ï
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    st.error("‚ö†Ô∏è API Key ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶Ø‡¶æ‡ßü‡¶®‡¶ø!")
    st.stop()

# ‡¶∏‡ßá‡¶∂‡¶® ‡¶∏‡ßç‡¶ü‡ßá‡¶ü (‡¶Æ‡ßá‡¶Æ‡ßã‡¶∞‡¶ø)
if "vector_store" not in st.session_state:
    st.session_state.vector_store = None
if "uploaded_file_path" not in st.session_state:
    st.session_state.uploaded_file_path = None

# --- ‡ßß. ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ---
uploaded_file = st.file_uploader("‡¶≤‡ßá‡¶ï‡¶ö‡¶æ‡¶∞ ‡¶∏‡ßç‡¶≤‡¶æ‡¶á‡¶° (PDF) ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßã", type=['pdf'])

if uploaded_file:
    # ‡¶ü‡ßá‡¶Æ‡ßç‡¶™ ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶ö‡ßá‡¶ï
    if not os.path.exists("temp_files"):
        os.makedirs("temp_files")
    
    # ‡¶´‡¶æ‡¶á‡¶≤ ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡¶æ
    file_path = os.path.join("temp_files", uploaded_file.name)
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    # ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶• ‡¶∏‡ßá‡¶∂‡¶®‡ßá ‡¶∞‡¶æ‡¶ñ‡¶æ
    st.session_state.uploaded_file_path = file_path

    if st.button("üß† ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡ßÅ‡¶®"):
        with st.spinner("‡¶¨‡ßç‡¶∞‡ßá‡¶á‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶π‡¶ö‡ßç‡¶õ‡ßá..."):
            try:
                loader = PyPDFLoader(file_path)
                pages = loader.load()

                text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
                chunks = text_splitter.split_documents(pages)
                
                embeddings = OpenAIEmbeddings()
                vector_store = FAISS.from_documents(chunks, embeddings)
                
                st.session_state.vector_store = vector_store
                st.success(f"‚úÖ ‡¶∏‡¶Æ‡ßç‡¶™‡¶®‡ßç‡¶®! {len(pages)} ‡¶™‡ßá‡¶ú ‡¶™‡ßú‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá‡•§")

            except Exception as e:
                st.error(f"Error: {e}")

st.write("---")

# --- ‡ß®. ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ì ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ---
user_question = st.text_input("‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ï‡¶∞‡ßã:")

if user_question and st.session_state.vector_store:
    
    retriever = st.session_state.vector_store.as_retriever()
    
    template = """Answer the question based ONLY on the following context:
    {context}
    
    Question: {question}
    """
    prompt = ChatPromptTemplate.from_template(template)
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0)

    with st.spinner("‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶õ‡¶ø..."):
        try:
            # A. ‡¶°‡¶ï‡ßÅ‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶ñ‡ßã‡¶Å‡¶ú‡¶æ
            relevant_docs = retriever.invoke(user_question)
            
            # B. ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶¨‡¶æ‡¶®‡¶æ‡¶®‡ßã
            context_text = "\n\n".join([d.page_content for d in relevant_docs])
            
            # C. ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶ü
            formatted_prompt = prompt.invoke({"context": context_text, "question": user_question})
            response = llm.invoke(formatted_prompt)
            
            # D. ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®‡ßã
            st.success("ü§ñ AI ‡¶â‡¶§‡ßç‡¶§‡¶∞:")
            st.write(response.content)
            
            # E. ‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶è‡¶¨‡¶Ç ‡¶õ‡¶¨‡¶ø ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®‡ßã (‡¶≤‡ßÅ‡¶ï‡¶æ‡¶®‡ßã ‡¶Ö‡¶¨‡¶∏‡ßç‡¶•‡¶æ‡ßü ‡¶•‡¶æ‡¶ï‡¶¨‡ßá)
            st.markdown("---")
            st.subheader("üìå ‡¶∞‡ßá‡¶´‡¶æ‡¶∞‡ßá‡¶®‡ßç‡¶∏ (‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶® ‡¶π‡¶≤‡ßá ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡ßá ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶®):")
            
            # ‡¶á‡¶â‡¶®‡¶ø‡¶ï ‡¶™‡ßá‡¶ú ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ
            unique_pages = set()
            for doc in relevant_docs:
                page_num = doc.metadata.get('page', 0)
                unique_pages.add(page_num)
            
            if st.session_state.uploaded_file_path:
                pdf_doc = fitz.open(st.session_state.uploaded_file_path)
                
                cols = st.columns(len(unique_pages))
                
                for idx, page_num in enumerate(sorted(unique_pages)):
                    # CHANGE HERE: expanded=False ‡¶ï‡¶∞‡ßá ‡¶¶‡ßá‡¶ì‡ßü‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá
                    with st.expander(f"üìÑ Page {page_num + 1} (Click to View Slide)", expanded=False):
                        st.info(f"Source: Page {page_num + 1}")
                        
                        page = pdf_doc.load_page(page_num)
                        pix = page.get_pixmap(dpi=150)
                        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                        
                        st.image(img, caption=f"Slide Page: {page_num + 1}", use_container_width=True)

        except Exception as e:
            st.error(f"Error: {e}")

elif user_question and not st.session_state.vector_store:
    st.warning("‚ö†Ô∏è ‡¶Ü‡¶ó‡ßá ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶ï‡¶∞‡ßã!")